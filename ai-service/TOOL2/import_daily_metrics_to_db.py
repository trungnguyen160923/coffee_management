"""
Script ƒë·ªÉ import d·ªØ li·ªáu t·ª´ daily_metrics.csv v√†o b·∫£ng daily_branch_metrics

Logic:
1. ƒê·ªçc CSV t·ª´ daily_metrics.csv
2. Map ng√†y: d√≤ng cu·ªëi (2018-10-17) -> 08/11/2025, c√°c d√≤ng tr∆∞·ªõc ƒë√≥ s·∫Ω l√† c√°c ng√†y tr∆∞·ªõc ƒë√≥
3. Convert UUID (top_selling_product_id) sang INT (v·ªõi mapping ƒë·ªÉ gi·ªØ consistency)
4. Insert v√†o database
"""
import os
import sys
import json
import pandas as pd
from datetime import date, datetime, timedelta
from pathlib import Path

# Add src to path
sys.path.insert(0, str(Path(__file__).parent / 'src'))

from src.infrastructure.database.connection import DatabaseConnection
from src.infrastructure.repositories.metrics_repository_impl import MetricsRepositoryImpl
from src.domain.entities.metrics import DailyBranchMetrics


def load_uuid_mapping(mapping_file: Path) -> dict:
    """Load UUID mapping t·ª´ file n·∫øu c√≥"""
    if mapping_file.exists():
        with open(mapping_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {}


def save_uuid_mapping(mapping: dict, mapping_file: Path):
    """L∆∞u UUID mapping v√†o file"""
    with open(mapping_file, 'w', encoding='utf-8') as f:
        json.dump(mapping, f, indent=2, ensure_ascii=False)


def create_uuid_to_int_mapping(df: pd.DataFrame, mapping_file: Path) -> dict:
    """
    T·∫°o mapping t·ª´ UUID sang INT cho top_selling_product_id
    - N·∫øu UUID ƒë√£ c√≥ trong mapping file th√¨ d√πng ID c≈©
    - N·∫øu ch∆∞a c√≥ th√¨ t·∫°o ID m·ªõi theo th·ª© t·ª± (1, 2, 3, ...)
    """
    # Load mapping c≈©
    uuid_to_int = load_uuid_mapping(mapping_file)
    
    # T√¨m ID l·ªõn nh·∫•t hi·ªán c√≥ (ƒë·ªÉ ti·∫øp t·ª•c ƒë√°nh s·ªë)
    max_id = max(uuid_to_int.values()) if uuid_to_int else 0
    next_id = max_id + 1
    
    # L·∫•y t·∫•t c·∫£ UUID trong CSV (theo th·ª© t·ª± xu·∫•t hi·ªán)
    # D√πng drop_duplicates(keep='first') ƒë·ªÉ gi·ªØ th·ª© t·ª±
    unique_uuids = df['top_selling_product_id'].dropna().drop_duplicates(keep='first')
    new_uuids = []
    
    for uuid in unique_uuids:
        if pd.isna(uuid) or uuid == '':
            continue
        
        uuid_str = str(uuid)
        
        # N·∫øu UUID ch∆∞a c√≥ trong mapping, t·∫°o ID m·ªõi
        if uuid_str not in uuid_to_int:
            uuid_to_int[uuid_str] = next_id
            new_uuids.append((uuid_str, next_id))
            next_id += 1
    
    # L∆∞u mapping m·ªõi
    if new_uuids:
        save_uuid_mapping(uuid_to_int, mapping_file)
        print(f"   ‚úÖ ƒê√£ th√™m {len(new_uuids)} UUID m·ªõi v√†o mapping:")
        print(f"      V√≠ d·ª•: {new_uuids[0][0][:20]}... -> {new_uuids[0][1]}")
        if len(new_uuids) > 1:
            print(f"      ... v√† {len(new_uuids)-1} UUID kh√°c")
    
    print(f"‚úÖ T·ªïng s·ªë UUID trong mapping: {len(uuid_to_int)}")
    return uuid_to_int


def map_dates_reverse(df: pd.DataFrame, target_end_date: date) -> pd.DataFrame:
    """
    Map ng√†y t·ª´ CSV v·ªÅ target_end_date tr·ªü v·ªÅ tr∆∞·ªõc
    D√≤ng cu·ªëi c√πng trong CSV s·∫Ω l√† target_end_date
    """
    df = df.copy()
    df['report_date'] = pd.to_datetime(df['report_date'], errors='coerce')
    
    # S·∫Øp x·∫øp theo ng√†y tƒÉng d·∫ßn (ƒë·ªÉ d√≤ng cu·ªëi l√† ng√†y m·ªõi nh·∫•t)
    df = df.sort_values('report_date').reset_index(drop=True)
    
    # D√≤ng cu·ªëi c√πng s·∫Ω l√† target_end_date
    last_row_idx = len(df) - 1
    last_csv_date = df.iloc[last_row_idx]['report_date'].date()
    
    # T√≠nh s·ªë ng√†y ch√™nh l·ªách
    days_diff = (target_end_date - last_csv_date).days
    
    # Map t·∫•t c·∫£ c√°c ng√†y
    df['mapped_date'] = df['report_date'].apply(
        lambda x: (x.date() + timedelta(days=days_diff)) if pd.notna(x) else None
    )
    
    print(f"üìÖ Map ng√†y:")
    print(f"   CSV cu·ªëi: {last_csv_date} -> DB: {target_end_date}")
    print(f"   CSV ƒë·∫ßu: {df.iloc[0]['report_date'].date()} -> DB: {df.iloc[0]['mapped_date']}")
    print(f"   CSV cu·ªëi: {df.iloc[-1]['report_date'].date()} -> DB: {df.iloc[-1]['mapped_date']}")
    print(f"   Ch√™nh l·ªách: {days_diff} ng√†y")
    
    # Verify: ki·ªÉm tra m·ªôt v√†i ng√†y ·ªü gi·ªØa
    if len(df) > 5:
        mid_idx = len(df) // 2
        print(f"   CSV gi·ªØa: {df.iloc[mid_idx]['report_date'].date()} -> DB: {df.iloc[mid_idx]['mapped_date']}")
    
    return df


def convert_row_to_entity(row: pd.Series, branch_id: int, uuid_to_int: dict) -> DailyBranchMetrics:
    """Convert CSV row th√†nh DailyBranchMetrics entity"""
    
    # Convert top_selling_product_id t·ª´ UUID sang INT
    top_product_uuid = row.get('top_selling_product_id')
    top_product_id = None
    if pd.notna(top_product_uuid) and top_product_uuid != '':
        uuid_str = str(top_product_uuid)
        top_product_id = uuid_to_int.get(uuid_str)
        
        # Validation: ƒë·∫£m b·∫£o UUID ƒë√£ c√≥ trong mapping
        if top_product_id is None:
            raise ValueError(f"UUID '{uuid_str}' kh√¥ng c√≥ trong mapping! C·∫ßn t·∫°o mapping tr∆∞·ªõc.")
    
    # Convert c√°c gi√° tr·ªã
    def safe_int(val):
        if pd.isna(val):
            return None
        try:
            return int(val)
        except:
            return None
    
    def safe_float(val):
        if pd.isna(val):
            return None
        try:
            return float(val)
        except:
            return None
    
    def safe_bool(val):
        if pd.isna(val):
            return None
        try:
            return bool(int(val))
        except:
            return None
    
    # L·∫•y mapped_date (ng√†y ƒë√£ ƒë∆∞·ª£c map)
    mapped_date = row['mapped_date']
    
    # T√≠nh l·∫°i day_of_week v√† is_weekend d·ª±a tr√™n mapped_date m·ªõi
    if mapped_date:
        # day_of_week: 1=Monday, 7=Sunday (ISO format)
        day_of_week = mapped_date.isoweekday()
        # is_weekend: True n·∫øu l√† Saturday (6) ho·∫∑c Sunday (7)
        is_weekend = day_of_week >= 6
    else:
        # Fallback: d√πng gi√° tr·ªã t·ª´ CSV n·∫øu kh√¥ng c√≥ mapped_date
        day_of_week = safe_int(row.get('day_of_week'))
        is_weekend = safe_bool(row.get('is_weekend'))
    
    return DailyBranchMetrics(
        branch_id=branch_id,
        report_date=mapped_date,
        total_revenue=safe_float(row.get('total_revenue')),
        order_count=safe_int(row.get('order_count')),
        avg_order_value=safe_float(row.get('avg_order_value')),
        customer_count=safe_int(row.get('customer_count')),
        repeat_customers=safe_int(row.get('repeat_customers')),
        new_customers=safe_int(row.get('new_customers')),
        unique_products_sold=safe_int(row.get('unique_products_sold')),
        top_selling_product_id=top_product_id,
        product_diversity_score=safe_float(row.get('product_diversity_score')),
        peak_hour=safe_int(row.get('peak_hour')),
        day_of_week=day_of_week,  # T√≠nh l·∫°i t·ª´ mapped_date
        is_weekend=is_weekend,     # T√≠nh l·∫°i t·ª´ mapped_date
        avg_review_score=safe_float(row.get('avg_review_score')),
        # C√°c tr∆∞·ªùng kh√¥ng c√≥ trong CSV s·∫Ω l√† None
        avg_preparation_time_seconds=None,
        staff_efficiency_score=None,
        material_cost=None,
        waste_percentage=None,
        low_stock_products=None,
        out_of_stock_products=None
    )


def main():
    """Main function"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Import daily_metrics.csv v√†o database")
    parser.add_argument("--csv", dest="csv_path", 
                       default="clean_data/daily_metrics.csv",
                       help="ƒê∆∞·ªùng d·∫´n ƒë·∫øn file CSV")
    parser.add_argument("--branch-id", dest="branch_id", type=int, default=1,
                       help="ID chi nh√°nh (m·∫∑c ƒë·ªãnh: 1)")
    parser.add_argument("--target-date", dest="target_date", 
                       default="2025-11-08",
                       help="Ng√†y cu·ªëi c√πng (d√≤ng cu·ªëi CSV s·∫Ω map v·ªÅ ng√†y n√†y, format: YYYY-MM-DD)")
    parser.add_argument("--dry-run", action="store_true",
                       help="Ch·ªâ hi·ªÉn th·ªã th√¥ng tin, kh√¥ng insert v√†o DB")
    parser.add_argument("--mapping-file", dest="mapping_file",
                       default="uuid_to_int_mapping.json",
                       help="File l∆∞u mapping UUID -> INT (m·∫∑c ƒë·ªãnh: uuid_to_int_mapping.json)")
    
    args = parser.parse_args()
    
    # Mapping file path
    mapping_file = Path(args.mapping_file)
    
    # Parse target date
    try:
        target_end_date = datetime.strptime(args.target_date, "%Y-%m-%d").date()
    except ValueError:
        print(f"‚ùå Invalid date format: {args.target_date}. Use YYYY-MM-DD")
        sys.exit(1)
    
    # ƒê·ªçc CSV
    csv_path = Path(args.csv_path)
    if not csv_path.exists():
        print(f"‚ùå File kh√¥ng t·ªìn t·∫°i: {csv_path}")
        sys.exit(1)
    
    print(f"üìñ ƒê·ªçc CSV: {csv_path}")
    df = pd.read_csv(csv_path)
    print(f"   T·ªïng s·ªë d√≤ng: {len(df)}")
    
    # T·∫°o UUID mapping
    print(f"\nüîë T·∫°o UUID to INT mapping (file: {mapping_file})...")
    uuid_to_int = create_uuid_to_int_mapping(df, mapping_file)
    
    # Ki·ªÉm tra: ƒë·∫£m b·∫£o t·∫•t c·∫£ UUID trong CSV ƒë·ªÅu c√≥ trong mapping
    all_uuids = df['top_selling_product_id'].dropna().unique()
    missing_uuids = [str(uuid) for uuid in all_uuids if str(uuid) not in uuid_to_int and str(uuid) != '']
    if missing_uuids:
        print(f"‚ö†Ô∏è  C·∫£nh b√°o: C√≥ {len(missing_uuids)} UUID kh√¥ng c√≥ trong mapping!")
        print(f"   V√≠ d·ª•: {missing_uuids[0]}")
    else:
        print(f"‚úÖ T·∫•t c·∫£ UUID trong CSV ƒë·ªÅu c√≥ trong mapping")
    
    # Map ng√†y
    print("\nüìÖ Map ng√†y...")
    df = map_dates_reverse(df, target_end_date)
    
    # K·∫øt n·ªëi DB
    if not args.dry_run:
        print("\nüîå K·∫øt n·ªëi database...")
        db = DatabaseConnection()
        try:
            db.connect()
            print("‚úÖ K·∫øt n·ªëi th√†nh c√¥ng")
        except Exception as e:
            print(f"‚ùå L·ªói k·∫øt n·ªëi database: {e}")
            sys.exit(1)
        
        metrics_repo = MetricsRepositoryImpl(db)
    else:
        print("\n‚ö†Ô∏è  DRY RUN mode - kh√¥ng insert v√†o DB")
        db = None
        metrics_repo = None
    
    # Import t·ª´ng d√≤ng
    print(f"\nüì• Import d·ªØ li·ªáu (branch_id={args.branch_id})...")
    success_count = 0
    error_count = 0
    
    for idx, row in df.iterrows():
        try:
            # Convert row to entity
            entity = convert_row_to_entity(row, args.branch_id, uuid_to_int)
            
            if args.dry_run:
                # Hi·ªÉn th·ªã t·∫•t c·∫£ c√°c gi√° tr·ªã c√≥ th·ªÉ l∆∞u
                print(f"\n   [{idx+1}/{len(df)}] {entity.report_date}:")
                print(f"      Revenue: {entity.total_revenue}, Orders: {entity.order_count}, AOV: {entity.avg_order_value}")
                print(f"      Customers: {entity.customer_count} (new: {entity.new_customers}, repeat: {entity.repeat_customers})")
                print(f"      Products: unique={entity.unique_products_sold}, top_id={entity.top_selling_product_id}, diversity={entity.product_diversity_score}")
                print(f"      Time: peak_hour={entity.peak_hour}, dow={entity.day_of_week}, weekend={entity.is_weekend}")
                print(f"      Review: {entity.avg_review_score}")
                
                # Ch·ªâ hi·ªÉn th·ªã 10 d√≤ng ƒë·∫ßu ƒë·ªÉ kh√¥ng qu√° d√†i
                if idx + 1 >= 10:
                    print(f"\n   ... (ch·ªâ hi·ªÉn th·ªã 10 d√≤ng ƒë·∫ßu, t·ªïng c·ªông {len(df)} d√≤ng)")
                    break
            else:
                # Insert v√†o DB
                metric_id = metrics_repo.save(entity)
                success_count += 1
                
                if (idx + 1) % 100 == 0:
                    print(f"   ƒê√£ import {idx + 1}/{len(df)} d√≤ng...")
        
        except Exception as e:
            error_count += 1
            print(f"   ‚ùå L·ªói ·ªü d√≤ng {idx+1}: {e}")
            if not args.dry_run:
                import traceback
                traceback.print_exc()
    
    # T·ªïng k·∫øt
    print("\n" + "="*60)
    print("üìä T·ªîNG K·∫æT")
    print("="*60)
    print(f"   T·ªïng s·ªë d√≤ng: {len(df)}")
    if not args.dry_run:
        print(f"   ‚úÖ Th√†nh c√¥ng: {success_count}")
        print(f"   ‚ùå L·ªói: {error_count}")
        if db:
            db.disconnect()
    else:
        print(f"   (DRY RUN - kh√¥ng c√≥ d·ªØ li·ªáu ƒë∆∞·ª£c insert)")
    print("="*60)


if __name__ == "__main__":
    main()

