"""
Train Isolation Forest t·ª´ database (daily_branch_metrics) v√† ƒë√°nh gi√° ƒë·ªô tin c·∫≠y.

Usage (PowerShell):
  python -m src.presentation.train_iforest_from_db ^
    --branch-id 1 ^
    --days 180 ^
    --n-estimators 200 ^
    --contamination 0.1 ^
    --model-version v1.0 ^
    --created-by "system" ^
    [--no-save]
"""
import argparse
import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from src.infrastructure.database.connection import DatabaseConnection
from src.infrastructure.ml.ml_trainer import MLTrainer
from src.infrastructure.repositories.metrics_repository_impl import MetricsRepositoryImpl
from src.infrastructure.repositories.model_repository_impl import ModelRepositoryImpl


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Train Isolation Forest from database")
    parser.add_argument("--branch-id", dest="branch_id", type=int, required=True,
                       help="ID chi nh√°nh")
    parser.add_argument("--days", dest="days", type=int, default=180,
                       help="S·ªë ng√†y d·ªØ li·ªáu ƒë·ªÉ train (m·∫∑c ƒë·ªãnh: 180)")
    parser.add_argument("--n-estimators", dest="n_estimators", type=int, default=200,
                       help="S·ªë trees trong Isolation Forest (m·∫∑c ƒë·ªãnh: 200)")
    parser.add_argument("--contamination", dest="contamination", type=float, default=0.1,
                       help="T·ª∑ l·ªá anomalies d·ª± ki·∫øn (m·∫∑c ƒë·ªãnh: 0.1)")
    parser.add_argument("--model-version", dest="model_version", default="v1.0",
                       help="Phi√™n b·∫£n model (m·∫∑c ƒë·ªãnh: v1.0)")
    parser.add_argument("--created-by", dest="created_by", default="system",
                       help="Ng∆∞·ªùi t·∫°o model (m·∫∑c ƒë·ªãnh: system)")
    parser.add_argument("--no-save", dest="no_save", action="store_true",
                       help="Kh√¥ng l∆∞u model v√†o database (ch·ªâ train v√† hi·ªÉn th·ªã k·∫øt qu·∫£)")
    return parser.parse_args()


def main() -> None:
    args = parse_args()

    print("="*80)
    print("üöÄ TRAIN ISOLATION FOREST FROM DATABASE")
    print("="*80)
    print(f"Branch ID: {args.branch_id}")
    print(f"Days: {args.days}")
    print(f"Hyperparameters: n_estimators={args.n_estimators}, contamination={args.contamination}")
    print(f"Model Version: {args.model_version}")
    if args.no_save:
        print(f"‚ö†Ô∏è  MODE: DRY RUN (kh√¥ng l∆∞u v√†o database)")
    print()

    print("üîå K·∫øt n·ªëi database...")
    try:
        db = DatabaseConnection()
        db.connect()
        print("‚úÖ K·∫øt n·ªëi th√†nh c√¥ng")
    except Exception as e:
        print(f"‚ùå L·ªói k·∫øt n·ªëi database: {e}")
        sys.exit(1)

    try:
        metrics_repo = MetricsRepositoryImpl(db)
        ml_trainer = MLTrainer()

        # L·∫•y d·ªØ li·ªáu training
        print(f"\nüìä ƒêang l·∫•y d·ªØ li·ªáu training...")
        metrics_list = metrics_repo.find_for_training(args.branch_id, args.days)
        
        if len(metrics_list) < 10:
            raise ValueError(f"Kh√¥ng ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ train (c·∫ßn √≠t nh·∫•t 10 samples, c√≥ {len(metrics_list)})")
        
        print(f"‚úÖ ƒê√£ l·∫•y {len(metrics_list)} samples")
        
        # Train model
        print(f"\nüìä ƒêang train model...")
        model, scaler, metadata = ml_trainer.train(
            metrics_list,
            n_estimators=args.n_estimators,
            contamination=args.contamination
        )
        
        # L∆∞u model v√†o DB (n·∫øu kh√¥ng c√≥ --no-save)
        model_id = None
        if not args.no_save:
            model_repo = ModelRepositoryImpl(db)
            model_id = ml_trainer.save_model_to_repository(
                model_repo,
                args.branch_id,
                model,
                scaler,
                metadata,
                args.model_version,
                args.created_by
            )

        print("\n" + "="*80)
        print("‚úÖ TRAIN TH√ÄNH C√îNG")
        print("="*80)

        print(f"\nüìä TH√îNG TIN TRAINING:")
        print(f"   Samples: {metadata['training_samples']}")
        print(f"   Date Range: {metadata['training_date_start']} ‚Üí {metadata['training_date_end']}")
        print(f"   Features: {len(metadata['feature_stats'])} features")

        print(f"\nüîç PH√ÅT HI·ªÜN ANOMALIES:")
        print(f"   Anomalies detected: {metadata['anomalies_in_training']} ({metadata['anomaly_rate']*100:.2f}%)")
        print(f"   Normal samples: {metadata['normal_samples']} ({(1-metadata['anomaly_rate'])*100:.2f}%)")
        print(f"   Expected contamination: {metadata['expected_contamination']*100:.2f}%")

        print(f"\nüìà ANOMALY SCORES (t·ªïng qu√°t):")
        print(f"   Mean: {metadata['mean_anomaly_score']:.4f}")
        print(f"   Std:  {metadata['std_anomaly_score']:.4f}")
        print(f"   Min:  {metadata['min_anomaly_score']:.4f}")
        print(f"   Max:  {metadata['max_anomaly_score']:.4f}")
        print(f"   Median: {metadata['median_anomaly_score']:.4f}")
        print(f"   Q25: {metadata['q25_anomaly_score']:.4f} | Q75: {metadata['q75_anomaly_score']:.4f}")

        if metadata.get('normal_mean_score') is not None:
            print(f"\n‚úÖ NORMAL SAMPLES:")
            print(f"   Mean score: {metadata['normal_mean_score']:.4f}")
            print(f"   Std score:  {metadata['normal_std_score']:.4f}")

        if metadata.get('anomaly_mean_score') is not None:
            print(f"\n‚ö†Ô∏è  ANOMALY SAMPLES:")
            print(f"   Mean score: {metadata['anomaly_mean_score']:.4f}")
            print(f"   Std score:  {metadata['anomaly_std_score']:.4f}")
            print(f"   Min score:  {metadata['anomaly_min_score']:.4f}")
            print(f"   Max score:  {metadata['anomaly_max_score']:.4f}")

        print(f"\n‚öôÔ∏è  HYPERPARAMETERS:")
        print(f"   n_estimators: {metadata['n_estimators']}")
        print(f"   contamination: {metadata['contamination']}")
        
        if metadata.get('threshold_score') is not None:
            print(f"\nüéØ THRESHOLD (Contamination Rate Method):")
            print(f"   Threshold Score: {metadata['threshold_score']:.4f}")
            print(f"   Threshold Percentile: {100.0 * (1.0 - metadata['contamination']):.1f}th percentile")
            print(f"   ‚úÖ S·ª≠ d·ª•ng ph∆∞∆°ng ph√°p Contamination Rate (ch√≠nh x√°c h∆°n IQR method)")

        if args.no_save:
            print(f"\nüíæ MODEL (KH√îNG L∆ØU V√ÄO DATABASE):")
            print(f"   ‚ö†Ô∏è  Model ƒë√£ ƒë∆∞·ª£c train nh∆∞ng KH√îNG ƒë∆∞·ª£c l∆∞u v√†o database")
            print(f"   Model Name: iforest_anomaly_branch_{args.branch_id}")
            print(f"   Model Version: {args.model_version}")
            print(f"   üí° S·ª≠ d·ª•ng --no-save ƒë·ªÉ test model tr∆∞·ªõc khi l∆∞u")
        else:
            print(f"\nüíæ MODEL ƒê√É ƒê∆Ø·ª¢C L∆ØU:")
            print(f"   Model ID: {model_id}")
            print(f"   Model Name: iforest_anomaly_branch_{args.branch_id}")
            print(f"   Model Version: {args.model_version}")
            print(f"   Location: b·∫£ng ml_models (database: analytics_db)")
            print(f"   Status: is_active=TRUE, is_production=FALSE")

        print(f"\nüéØ ƒê√ÅNH GI√Å CH·∫§T L∆Ø·ª¢NG MODEL:")
        score_separation = None
        if metadata.get('normal_mean_score') is not None and metadata.get('anomaly_mean_score') is not None:
            score_separation = abs(metadata['normal_mean_score'] - metadata['anomaly_mean_score'])
            print(f"   Score separation: {score_separation:.4f}")
            if score_separation > 0.1:
                print("   ‚úÖ T·ªët: Model ph√¢n bi·ªát r√µ r√†ng gi·ªØa normal v√† anomaly")
            elif score_separation > 0.05:
                print("   ‚ö†Ô∏è  Trung b√¨nh: Model c√≥ kh·∫£ nƒÉng ph√¢n bi·ªát nh∆∞ng c·∫ßn c·∫£i thi·ªán")
            else:
                print("   ‚ùå Y·∫øu: Model kh√≥ ph√¢n bi·ªát gi·ªØa normal v√† anomaly")

        anomaly_rate_diff = abs(metadata['anomaly_rate'] - metadata['expected_contamination'])
        print(f"   Anomaly rate difference: {anomaly_rate_diff*100:.2f}%")
        if anomaly_rate_diff < 0.02:
            print("   ‚úÖ T·ªët: T·ª∑ l·ªá anomaly ph√°t hi·ªán g·∫ßn v·ªõi contamination rate")
        elif anomaly_rate_diff < 0.05:
            print("   ‚ö†Ô∏è  Trung b√¨nh: T·ª∑ l·ªá anomaly c√≥ s·ª± kh√°c bi·ªát nh·ªè")
        else:
            print("   ‚ö†Ô∏è  Ch√∫ √Ω: T·ª∑ l·ªá anomaly kh√°c bi·ªát ƒë√°ng k·ªÉ v·ªõi contamination rate")

        print(f"\nüìä CLASSIFICATION METRICS:")
        if metadata.get('accuracy_score') is not None:
            print(f"   ‚ö†Ô∏è  L∆ØU √ù: {metadata.get('note', '')}")
            print(f"   Accuracy:  {metadata['accuracy_score']:.4f}")
            print(f"   Precision: {metadata['precision_score']:.4f}")
            print(f"   Recall:    {metadata['recall_score']:.4f}")
            print(f"   F1 Score:  {metadata['f1_score']:.4f}")
            if metadata.get('confusion_matrix'):
                cm = metadata['confusion_matrix']
                print(f"\n   Confusion Matrix:")
                print("   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê")
                print("   ‚îÇ             ‚îÇ  Predicted   ‚îÇ")
                print("   ‚îÇ             ‚îÇ Normal‚îÇAnomaly‚îÇ")
                print("   ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§")
                print("   ‚îÇ Actual      ‚îÇ      ‚îÇ       ‚îÇ")
                print(f"   ‚îÇ Normal      ‚îÇ {cm['true_negatives']:5d}‚îÇ {cm['false_positives']:5d}‚îÇ")
                print(f"   ‚îÇ Anomaly     ‚îÇ {cm['false_negatives']:5d}‚îÇ {cm['true_positives']:5d}‚îÇ")
                print("   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò")
        else:
            print("   ‚ö†Ô∏è  Kh√¥ng th·ªÉ t√≠nh classification metrics (c·∫ßn labeled data)")
            print("   ‚Üí Isolation Forest l√† unsupervised, thi·∫øu ground truth ƒë·ªÉ so s√°nh")

        print("="*80)

    except Exception as e:
        print(f"\n‚ùå L·ªói khi train: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
    finally:
        db.disconnect()


if __name__ == "__main__":
    main()

